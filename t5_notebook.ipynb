{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Specialty Classification with T5\n",
    "\n",
    "T5 (\"Text-to-Text Transfer Transformer\") is an encoder-decoder based model which was shown to be useful for many NLP tasks.\\\n",
    "The base of the work is a pretrained model on a large scale English text dataset. In this notebook, we finetune  it to the task of medical specialty classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports\n",
    "The code is written using **PyTorch**. \\\n",
    "T5 implementation was taken from **transformers** library by [huggingface](https://github.com/huggingface/transformers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hY92uROr8N10",
    "outputId": "3288ab84-0d22-4a08-9707-712f8644c879",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hagaymi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# task imports\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5Model,\n",
    "    T5ForConditionalGeneration,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAtXbuJF8Rw5",
    "outputId": "49cb1b45-3ff9-463e-9cdf-3318456e5bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs on google colab:  False\n",
      "root dir:  .\n"
     ]
    }
   ],
   "source": [
    "# check if running on google colab\n",
    "try:\n",
    "  import google.colab\n",
    "  IS_COLAB = True\n",
    "except:\n",
    "  IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "  # from google.colab import drive\n",
    "  # drive.mount('/content/drive')\n",
    "  # root_dir = '/content/drive/MyDrive/projects/8200bio/Nym/'\n",
    "  # install colab extensions\n",
    "  ! pip3 install transformers\n",
    "  ! pip install sentencepiece\n",
    "  ! pip install gdown\n",
    "# else:\n",
    "#     root_dir = '/home/hagaymi/nym/'\n",
    "root_dir = '.'\n",
    "print(\"runs on google colab: \", IS_COLAB)\n",
    "print(\"root dir: \", root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OZrRN5jLkL73E_ZchJYe0cmNy-WPbj5-\n",
      "To: /home/hagaymi/nym/data.csv\n",
      "100%|██████████████████████████████████████| 11.0M/11.0M [00:00<00:00, 17.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "! gdown --id 1OZrRN5jLkL73E_ZchJYe0cmNy-WPbj5-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "The dataset contains approx. 2000 transcriptions labled by medical specialty. \\\n",
    "It was provided by Nym during 8200bio challenge (Oct. 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "iFQGl5Wc8jlj",
    "outputId": "1f463495-a190-4a56-eb5a-88387e21ec25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>DISCHARGE DIAGNOSES:,1.  End-stage renal disea...</td>\n",
       "      <td>Nephrology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Left carpal tunnel s...</td>\n",
       "      <td>Orthopedic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcription   specialty\n",
       "3409  DISCHARGE DIAGNOSES:,1.  End-stage renal disea...  Nephrology\n",
       "1774  PREOPERATIVE DIAGNOSIS:,  Left carpal tunnel s...  Orthopedic"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw dataset\n",
    "data = pd.read_csv(os.path.join(root_dir, 'data.csv'))\n",
    "data.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "cQ0909I18sNG",
    "outputId": "32932340-d338-41a7-f2d4-e3c0d9c0dfab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.specialty.value_counts().plot(kind='barh',figsize=(5, 10), title='Transcriptions in each category' )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.  Pelvic tumor.,2.  Cystocele.,3.  Rectocele...</td>\n",
       "      <td>[Obstetrics / Gynecology, Surgery, Urology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Radiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Radiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Radiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-DIMENSIONAL SIMULATION,This patient is under...</td>\n",
       "      <td>[Hematology - Oncology, Radiology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  1.  Pelvic tumor.,2.  Cystocele.,3.  Rectocele...   \n",
       "1  1.  The left ventricular cavity size and wall ...   \n",
       "2  2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "3  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "4  3-DIMENSIONAL SIMULATION,This patient is under...   \n",
       "\n",
       "                                             0  \n",
       "0  [Obstetrics / Gynecology, Surgery, Urology]  \n",
       "1      [Cardiovascular / Pulmonary, Radiology]  \n",
       "2      [Cardiovascular / Pulmonary, Radiology]  \n",
       "3      [Cardiovascular / Pulmonary, Radiology]  \n",
       "4           [Hematology - Oncology, Radiology]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.groupby('transcription').apply(lambda x: x['specialty'].values.tolist()).reset_index()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "5RIXMwef8xQr",
    "outputId": "99ea628d-6754-4990-d77f-1febf6b5ba27"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWQ0lEQVR4nO3de9RddX3n8fdHAqLxAmoWCxIEpqAU7bTaFOzQpVRaBGoNq6OOTlXUtBln0HqtIE7Fy9Slqx1v1bFNhRbUBTqoA0upilxktAImCCgXh4gCCZdE7hRvyHf+OD/M4eF58ksgz9lPeN6vtc46e//2b+/9PZtwPmf/9jn7SVUhSdKmPGLoAiRJc59hIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCc0qSc5P82aTXFSQ5NsknHsL6/5LkyK1Zk+YOw0KzIsmPkvzB0HUMLclBSdYOXcfmqKr3VtVmhW2Sdyb51JT1D6uqE2enOg3NsJC2kiQLJrne1jQXatDcZlhoopLsnOSLSTYkubVNL5nS7deSXJjkjiSnJXnC2PrPSvKvSW5LckmSg2bYz95Jvp7k9iQ/TvKZGfrtmaSSrEhyfZIbkrxlbPkjkhyT5AdJbk7y2fvqGVt3eZJrgbOnbHsh8C/Abknuao/d2qfyU5N8KskdwCuT7J/kW+113ZDko0l2GNtWJXlNkqtan48lSe+1JnlakjOT3JLkpiTHtvbpavjV2cKmjkuSQ4Fjgf/UXtMlrf1Xw4DtuP33JNckWZ/kpCSPn7LtI5Nc22p++/T/YjRXGBaatEcA/wTsATwZ+Anw0Sl9XgG8GtgVuAf4CECSxcCXgP8BPAF4C/C5JIum2c97gK8COwNLgL/r1PX7wD7AIcDRY0NorwOOAJ4D7AbcCnxsyrrPAX4deN54Y1X9G3AYcH1VPaY9rm+LlwGnAjsBnwZ+CbwReBLwu8DBwH+bsp/nA78D/HvgxWP7m/a1Jnks8DXgy632vYGzxrY3tYbNOi5V9WXgvcBn2mv6zWnWe2V7/D7w74DH8MD/zr8HPLW91nck+fUZatAcYFhooqrq5qr6XFXdXVV3An/N6M123Cer6nvtzfavgBcn2Q54GXBGVZ1RVfdW1ZnAKuDwaXb1C0aBtFtV/bSqvtEp7V1V9W9V9V1GYfbS1v4a4O1Vtbaqfga8E3jhlGGbd7Z1f7LZBwK+VVX/p72On1TV6qo6v6ruqaofAf/AA4/L+6rqtqq6FjgH+K3Oa30+cGNV/c/WfmdVXTBTDVt4XHr+FPhAVV1dVXcBbwNeMuW4vau99kuAS4DpQkdzhGGhiUry6CT/0IYn7gDOA3ZqYXCf68amrwG2Z/SJew/gRW0Y5rYktzH6dLrrNLt6KxDgwiSXJXl1p7Sp+9ytTe8BfGFsf1cwOgvYZYZ1N9f91knylDYkd2M7Lu9l9JrH3Tg2fTejT+sw82vdHfjB5tawGX3Gj0vPbq3/+LoLuP9xm+n1aA4yLDRpb2Y09HBAVT0OeHZrz1if3cemn8zok/OPGb1xfbKqdhp7LKyq903dSVXdWFV/XlW7Af8F+F9J9t5EXVP3ed9w0XXAYVP2uWNVrRvf3Sa2O9Oyqe0fB64E9mnH5Vjuf0xm3sHMr/U6RkNAW1rbuJmOS2/d6xkF7fi69wA3bcY+NQcZFppN2yfZceyxAHgso+sUt7ULxcdNs97LkuyX5NHAu4FTq+qXwKeAP07yvCTbtW0elAdeICfJi8bab2X05nbvJmr9q3bW8zTgVcB9F4n/HvjrJHu07S5KsmwLjsFNwBPvu7i7CY8F7gDuSrIv8F83dwebeK1fBHZN8oYkj0zy2CQHbEHtMPNxuQnYM8lM7yEnA29MsleSx7DxGsc9W7h/zRGGhWbTGYyC4b7HO4EPAY9idKZwPqOLr1N9EvhnRsMUOwJ/AVBV1zG6KHsssIHRJ+e/ZPp/x78DXJDkLuB04PVVdfUmav06sIbRBeC/raqvtvYPt/W/muTOVvNmv+FW1ZWM3jivbkNZMw3jvAX4z8CdwD+y8U15c0z7Wts1oT8E/pjRsbyK0QXnLTHTcfnf7fnmJBdNs94JjP47ngf8EPgpoy8LaBsV//iR5rMkezJ6M9veT70beVw0lWcWkqSuWQuLJCe0H+N8b6ztb5JcmeTSJF9IstPYsrclWZPk+0meN9Z+aGtbk+SY2apXkjSzWRuGSvJs4C7gpKp6ems7BDi7qu5J8n6Aqjo6yX6MxnX3Z/SVu68BT2mb+n+Mxl3XAt8GXlpVl89K0ZKkac3amUVVnQfcMqXtq2Pjn+cz+rUpjC5anlJVP6uqHzK6oLZ/e6xpF+t+DpzS+kqSJmjIm4e9mo3f+FjMKDzus7a1wf1/FLSWGb6JkmQFsAJg4cKFv73vvvtu1WIl6eFu9erVP66q6W6fM0xYtJuG3cPM96PZYlW1ElgJsHTp0lq1atXW2rQkzQtJrplp2cTDIskrGd2z5uDaeMFkHff/peiS1sYm2iVJEzLRr862Wxu/FXhBVd09tuh0RjcZe2SSvRjd5fJCRhe092m/At0BeEnrK0maoFk7s0hyMnAQ8KSM/lLYcYzuPPlI4MyMbsV/flW9pqouS/JZ4HJGw1NHtds7kOS1wFeA7YATquqy2apZkjS9h+UvuL1mIUlbLsnqqlo63TJ/wS1J6jIsJEldhoUkqcuwkCR1GRaSpK4hb/ehgV377t8YuoRZ8eR3fHfoEqSHHc8sJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktQ1a2GR5IQk65N8b6ztCUnOTHJVe965tSfJR5KsSXJpkmeOrXNk639VkiNnq15J0sxm88zin4FDp7QdA5xVVfsAZ7V5gMOAfdpjBfBxGIULcBxwALA/cNx9ASNJmpxZC4uqOg+4ZUrzMuDENn0icMRY+0k1cj6wU5JdgecBZ1bVLVV1K3AmDwwgSdIsm/Q1i12q6oY2fSOwS5teDFw31m9ta5upXZI0QYNd4K6qAmprbS/JiiSrkqzasGHD1tqsJInJh8VNbXiJ9ry+ta8Ddh/rt6S1zdT+AFW1sqqWVtXSRYsWbfXCJWk+m3RYnA7c942mI4HTxtpf0b4V9Szg9jZc9RXgkCQ7twvbh7Q2SdIELZitDSc5GTgIeFKStYy+1fQ+4LNJlgPXAC9u3c8ADgfWAHcDrwKoqluSvAf4duv37qqaetFckjTLZi0squqlMyw6eJq+BRw1w3ZOAE7YiqVJkraQv+CWJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugYJiyRvTHJZku8lOTnJjkn2SnJBkjVJPpNkh9b3kW1+TVu+5xA1S9J8NvGwSLIY+AtgaVU9HdgOeAnwfuCDVbU3cCuwvK2yHLi1tX+w9ZMkTdBQw1ALgEclWQA8GrgBeC5walt+InBEm17W5mnLD06SyZUqSZp4WFTVOuBvgWsZhcTtwGrgtqq6p3VbCyxu04uB69q697T+T5y63SQrkqxKsmrDhg2z+yIkaZ4ZYhhqZ0ZnC3sBuwELgUMf6naramVVLa2qpYsWLXqom5MkjRliGOoPgB9W1Yaq+gXweeBAYKc2LAWwBFjXptcBuwO05Y8Hbp5syZI0vw0RFtcCz0ry6Hbt4WDgcuAc4IWtz5HAaW369DZPW352VdUE65WkeW+IaxYXMLpQfRHw3VbDSuBo4E1J1jC6JnF8W+V44Imt/U3AMZOuWZLmuwX9LltfVR0HHDel+Wpg/2n6/hR40STqkiRNz19wS5K6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldg9xIcEi//ZcnDV3CrFj9N68YugRJD2OeWUiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdQ0SFkl2SnJqkiuTXJHkd5M8IcmZSa5qzzu3vknykSRrklya5JlD1CxJ89lQZxYfBr5cVfsCvwlcARwDnFVV+wBntXmAw4B92mMF8PHJlytJ81v3jx8l2RdYBixuTeuA06vqigezwySPB54NvBKgqn4O/DzJMuCg1u1E4Fzg6Lbvk6qqgPPbWcmuVXXDg9m/JGnLbfLMIsnRwClAgAvbI8DJSY7Z1LqbsBewAfinJN9J8okkC4FdxgLgRmCXNr0YuG5s/bVsDK7xWlckWZVk1YYNGx5kaZKk6fTOLJYDT6uqX4w3JvkAcBnwvge5z2cCr6uqC5J8mI1DTgBUVSWpLdloVa0EVgIsXbp0i9aVJG1a75rFvcBu07Tv2pY9GGuBtVV1QZs/lVF43JRkV4D2vL4tXwfsPrb+ktYmSZqQ3pnFG4CzklzFxqGgJwN7A699MDusqhuTXJfkqVX1feBg4PL2OJLR2cqRwGltldOB1yY5BTgAuN3rFZI0WZsMi6r6cpKnAPtz/wvc366qXz6E/b4O+HSSHYCrgVcxOsv5bJLlwDXAi1vfM4DDgTXA3a2vJGmCut+Gqqp7gfO35k6r6mJg6TSLDp6mbwFHbc39S5K2jL/gliR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUNVhYJNkuyXeSfLHN75XkgiRrknwmyQ6t/ZFtfk1bvudQNUvSfDXkmcXrgSvG5t8PfLCq9gZuBZa39uXAra39g62fJGmCBgmLJEuAPwI+0eYDPBc4tXU5ETiiTS9r87TlB7f+kqQJGerM4kPAW4F72/wTgduq6p42vxZY3KYXA9cBtOW3t/73k2RFklVJVm3YsGEWS5ek+WfiYZHk+cD6qlq9NbdbVSuramlVLV20aNHW3LQkzXsLBtjngcALkhwO7Ag8DvgwsFOSBe3sYQmwrvVfB+wOrE2yAHg8cPPky5ak+WviZxZV9baqWlJVewIvAc6uqj8FzgFe2LodCZzWpk9v87TlZ1dVTbBkSZr35tLvLI4G3pRkDaNrEse39uOBJ7b2NwHHDFSfJM1bQwxD/UpVnQuc26avBvafps9PgRdNtDBJ0v3MpTMLSdIcZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroWDF2ANBcc+HcHDl3CrPjm6745dAl6mJj4mUWS3ZOck+TyJJcleX1rf0KSM5Nc1Z53bu1J8pEka5JcmuSZk65Zkua7IYah7gHeXFX7Ac8CjkqyH3AMcFZV7QOc1eYBDgP2aY8VwMcnX7IkzW8TD4uquqGqLmrTdwJXAIuBZcCJrduJwBFtehlwUo2cD+yUZNfJVi1J89ugF7iT7Ak8A7gA2KWqbmiLbgR2adOLgevGVlvb2iRJEzJYWCR5DPA54A1Vdcf4sqoqoLZweyuSrEqyasOGDVuxUknSIGGRZHtGQfHpqvp8a77pvuGl9ry+ta8Ddh9bfUlru5+qWllVS6tq6aJFi2aveEmah4b4NlSA44ErquoDY4tOB45s00cCp421v6J9K+pZwO1jw1WSpAkY4ncWBwIvB76b5OLWdizwPuCzSZYD1wAvbsvOAA4H1gB3A6+aaLWSpMmHRVV9A8gMiw+epn8BR81qUZKkTfJ2H5KkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXNhMWSQ5N8v0ka5IcM3Q9kjSfbBNhkWQ74GPAYcB+wEuT7DdsVZI0fywYuoDNtD+wpqquBkhyCrAMuHzQqqSHoa8/+zlDlzArnnPe14cuYZuWqhq6hq4kLwQOrao/a/MvBw6oqteO9VkBrGizTwW+P/FCH+hJwI+HLmKO8Fhs5LHYyGOx0Vw4FntU1aLpFmwrZxZdVbUSWDl0HeOSrKqqpUPXMRd4LDbyWGzksdhorh+LbeKaBbAO2H1sfklrkyRNwLYSFt8G9kmyV5IdgJcApw9ckyTNG9vEMFRV3ZPktcBXgO2AE6rqsoHL2hxzalhsYB6LjTwWG3ksNprTx2KbuMAtSRrWtjIMJUkakGEhSeoyLGZBkhOSrE/yvaFrGVKS3ZOck+TyJJclef3QNQ0lyY5JLkxySTsW7xq6pqEl2S7Jd5J8cehahpTkR0m+m+TiJKuGrmcmXrOYBUmeDdwFnFRVTx+6nqEk2RXYtaouSvJYYDVwRFXNu1/eJwmwsKruSrI98A3g9VV1/sClDSbJm4ClwOOq6vlD1zOUJD8CllbV0D/I2yTPLGZBVZ0H3DJ0HUOrqhuq6qI2fSdwBbB42KqGUSN3tdnt22PeflJLsgT4I+ATQ9eizWNYaCKS7Ak8A7hg4FIG04ZdLgbWA2dW1bw9FsCHgLcC9w5cx1xQwFeTrG63LZqTDAvNuiSPAT4HvKGq7hi6nqFU1S+r6rcY3YFg/yTzcogyyfOB9VW1euha5ojfq6pnMrqr9lFtGHvOMSw0q9r4/OeAT1fV54euZy6oqtuAc4BDBy5lKAcCL2hj9acAz03yqWFLGk5VrWvP64EvMLrL9pxjWGjWtIu6xwNXVNUHhq5nSEkWJdmpTT8K+EPgykGLGkhVva2qllTVnoxu3XN2Vb1s4LIGkWRh+/IHSRYChwBz8luUhsUsSHIy8C3gqUnWJlk+dE0DORB4OaNPjhe3x+FDFzWQXYFzklzK6F5nZ1bVvP7KqADYBfhGkkuAC4EvVdWXB65pWn51VpLU5ZmFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAvpIUjyr1vY/6D5fpdVbZsMC+khqKr/MHQN0iQYFtJDkOSu9nxQknOTnJrkyiSfbr9gJ8mhre0i4E/G1l3Y/vbJhe3vOixr7R9O8o42/bwk5yXx/1UNasHQBUgPI88AngZcD3wTOLD9MZt/BJ4LrAE+M9b/7YxudfHqdiuQC5N8DXgb8O0k/xf4CHB4VXl3Vg3KTyvS1nNhVa1tb+wXA3sC+wI/rKqranS7hPEb5h0CHNNuW34usCPw5Kq6G/hz4Ezgo1X1g4m9AmkGnllIW8/PxqZ/Sf//rwD/saq+P82y3wBuBnbbSrVJD4lnFtLsuhLYM8mvtfmXji37CvC6sWsbz2jPewBvZjSsdViSAyZYrzQtw0KaRVX1U2AF8KV2gXv92OL3MPrzqpcmuQx4z9ht3d9SVdcDy4FPJNlxwqVL9+NdZyVJXZ5ZSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrv8PyCiEmIzCRM0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcription_counts = data.groupby('transcription').size().value_counts().reset_index()\n",
    "p = sns.barplot(data = transcription_counts, x='index', y=0).set(title='Labels per transcription')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1U4JGRlCV6rU",
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypmZbRxV4TFb"
   },
   "source": [
    "We're using the raw transcription concatenated to the task decription: \\\n",
    "`classify specialties:`\n",
    "\n",
    "#### Abstracts\n",
    "- Stripping extra whitespaces around the text.\n",
    "- Replacing escape characters with whitespace.\n",
    "- Padding all punctuations with whitespaces on both sides.\n",
    "\n",
    "#### Labels\n",
    "Each transcription can have multiple lables, while each sample in the raw dataset has one label.\n",
    "We cancel repeatations, and instead attach label list to every transcription.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "MD7iAF-f1646",
    "outputId": "5fd03cf6-2c79-47f8-e4b1-85dde3800b74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHIEF COMPLAINT: , This 5-year-old male presen...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HISTORY: , A 34-year-old male presents today s...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HISTORY:,  I had the pleasure of meeting and e...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBJECTIVE: , This is a 42-year-old white fema...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription             specialty\n",
       "0  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...  Allergy / Immunology\n",
       "1  CHIEF COMPLAINT: , This 5-year-old male presen...  Allergy / Immunology\n",
       "2  HISTORY: , A 34-year-old male presents today s...  Allergy / Immunology\n",
       "3  HISTORY:,  I had the pleasure of meeting and e...  Allergy / Immunology\n",
       "4  SUBJECTIVE: , This is a 42-year-old white fema...  Allergy / Immunology"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data, initial preprocessing\n",
    "data = pd.read_csv(os.path.join(root_dir, 'data.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SK1b6b_5v2to",
    "outputId": "9bc27f45-6701-472b-96fb-c07742314946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label list:  ['Allergy / Immunology' 'Autopsy' 'Bariatrics'\n",
      " 'Cardiovascular / Pulmonary' 'Cosmetic / Plastic Surgery' 'Dentistry'\n",
      " 'Dermatology' 'ENT - Otolaryngology' 'Emergency Room Reports'\n",
      " 'Endocrinology' 'Gastroenterology' 'General Medicine'\n",
      " 'Hematology - Oncology' 'Hospice - Palliative Care'\n",
      " 'Lab Medicine - Pathology' 'Nephrology' 'Neurology' 'Neurosurgery'\n",
      " 'Obstetrics / Gynecology' 'Office Notes' 'Ophthalmology' 'Orthopedic'\n",
      " 'Pain Management' 'Pediatrics - Neonatal' 'Physical Medicine - Rehab'\n",
      " 'Podiatry' 'Psychiatry / Psychology' 'Radiology' 'Rheumatology'\n",
      " 'Sleep Medicine' 'Surgery' 'Urology' 'speciality']\n",
      "labels dict:  {'Allergy / Immunology': 0, 'allergy / immunology': 0, 'Allergy': 0, 'allergy': 0, 'Immunology': 0, 'immunology': 0, 'Allergy/Immunology': 0, 'allergy/immunology': 0, 'Autopsy': 1, 'autopsy': 1, 'Bariatrics': 2, 'bariatrics': 2, 'Cardiovascular / Pulmonary': 3, 'cardiovascular / pulmonary': 3, 'Cardiovascular': 3, 'cardiovascular': 3, 'Pulmonary': 3, 'pulmonary': 3, 'Cardiovascular/Pulmonary': 3, 'cardiovascular/pulmonary': 3, 'Cosmetic / Plastic Surgery': 4, 'cosmetic / plastic surgery': 4, 'Cosmetic': 4, 'cosmetic': 4, 'Plastic Surgery': 4, 'plastic surgery': 4, 'Cosmetic/PlasticSurgery': 4, 'cosmetic/plasticsurgery': 4, 'Dentistry': 5, 'dentistry': 5, 'Dermatology': 6, 'dermatology': 6, 'ENT - Otolaryngology': 7, 'ent - otolaryngology': 7, 'ENT-Otolaryngology': 7, 'ent-otolaryngology': 7, 'Emergency Room Reports': 8, 'emergency room reports': 8, 'EmergencyRoomReports': 8, 'emergencyroomreports': 8, 'Endocrinology': 9, 'endocrinology': 9, 'Gastroenterology': 10, 'gastroenterology': 10, 'General Medicine': 11, 'general medicine': 11, 'GeneralMedicine': 11, 'generalmedicine': 11, 'Hematology - Oncology': 12, 'hematology - oncology': 12, 'Hematology-Oncology': 12, 'hematology-oncology': 12, 'Hospice - Palliative Care': 13, 'hospice - palliative care': 13, 'Hospice-PalliativeCare': 13, 'hospice-palliativecare': 13, 'Lab Medicine - Pathology': 14, 'lab medicine - pathology': 14, 'LabMedicine-Pathology': 14, 'labmedicine-pathology': 14, 'Nephrology': 15, 'nephrology': 15, 'Neurology': 16, 'neurology': 16, 'Neurosurgery': 17, 'neurosurgery': 17, 'Obstetrics / Gynecology': 18, 'obstetrics / gynecology': 18, 'Obstetrics': 18, 'obstetrics': 18, 'Gynecology': 18, 'gynecology': 18, 'Obstetrics/Gynecology': 18, 'obstetrics/gynecology': 18, 'Office Notes': 19, 'office notes': 19, 'OfficeNotes': 19, 'officenotes': 19, 'Ophthalmology': 20, 'ophthalmology': 20, 'Orthopedic': 21, 'orthopedic': 21, 'Pain Management': 22, 'pain management': 22, 'PainManagement': 22, 'painmanagement': 22, 'Pediatrics - Neonatal': 23, 'pediatrics - neonatal': 23, 'Pediatrics-Neonatal': 23, 'pediatrics-neonatal': 23, 'Physical Medicine - Rehab': 24, 'physical medicine - rehab': 24, 'PhysicalMedicine-Rehab': 24, 'physicalmedicine-rehab': 24, 'Podiatry': 25, 'podiatry': 25, 'Psychiatry / Psychology': 26, 'psychiatry / psychology': 26, 'Psychiatry': 26, 'psychiatry': 26, 'Psychology': 26, 'psychology': 26, 'Psychiatry/Psychology': 26, 'psychiatry/psychology': 26, 'Radiology': 27, 'radiology': 27, 'Rheumatology': 28, 'rheumatology': 28, 'Sleep Medicine': 29, 'sleep medicine': 29, 'SleepMedicine': 29, 'sleepmedicine': 29, 'Surgery': 30, 'surgery': 30, 'Urology': 31, 'urology': 31, 'speciality': 32}\n"
     ]
    }
   ],
   "source": [
    "# fetch all labels\n",
    "labels_list = data['specialty'].unique()\n",
    "print(\"label list: \", labels_list)\n",
    "\n",
    "# set labels lower case. for options like 'Allergy / Immunology'\n",
    "# allow \"partial labels\" (e.g. 'Allergy'  'Immunology') \n",
    "labels_li_indices = dict()\n",
    "\n",
    "for idx, label in enumerate(labels_list):\n",
    "    labels_li_indices[label] = idx\n",
    "    labels_li_indices[label.lower()] = idx\n",
    "    if ' / ' in label:\n",
    "        for l in label.split(' / '):\n",
    "            labels_li_indices[l] = idx\n",
    "            labels_li_indices[l.lower()] = idx\n",
    "    labels_li_indices[label.replace(' ', '')] = idx\n",
    "    labels_li_indices[label.lower().replace(' ', '')] = idx\n",
    "    \n",
    "          \n",
    "print(\"labels dict: \", labels_li_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XhFmT7jQk5oa",
    "outputId": "defdacd4-57b9-4caa-fcd6-3edfe8e56d56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.  Pelvic tumor.,2.  Cystocele.,3.  Rectocele...</td>\n",
       "      <td>[Obstetrics / Gynecology, Surgery, Urology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Radiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Radiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>[Cardiovascular / Pulmonary, Radiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-DIMENSIONAL SIMULATION,This patient is under...</td>\n",
       "      <td>[Hematology - Oncology, Radiology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  1.  Pelvic tumor.,2.  Cystocele.,3.  Rectocele...   \n",
       "1  1.  The left ventricular cavity size and wall ...   \n",
       "2  2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "3  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "4  3-DIMENSIONAL SIMULATION,This patient is under...   \n",
       "\n",
       "                                             0  \n",
       "0  [Obstetrics / Gynecology, Surgery, Urology]  \n",
       "1      [Cardiovascular / Pulmonary, Radiology]  \n",
       "2      [Cardiovascular / Pulmonary, Radiology]  \n",
       "3      [Cardiovascular / Pulmonary, Radiology]  \n",
       "4           [Hematology - Oncology, Radiology]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unify duplicated text and set label list\n",
    "train_df = data.groupby('transcription').apply(lambda x: x['specialty'].values.tolist()).reset_index()\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fTMIgN3XrPc",
    "outputId": "62f0ed25-23c8-4456-cde2-243d854e72cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT -\tclassify specialties: 1 .  Pelvic tumor .  , 2 .  Cystocele .  , 3 .  Rectocele .  , POSTOPERATIVE DIAGNOSES: , 1 .  Degenerated joint .  , 2 .  Uterine fibroid .  , 3 .  Cystocele .  , 4 .  Rectocele .  , PROCEDURE PERFORMED:  , 1 .  Total abdominal hysterectomy .  , 2 .  Bilateral salpingooophorectomy .  , 3 .  Repair of bladder laceration .  , 4 .  Appendectomy .  , 5 .  Marshall-Marchetti-Krantz cystourethropexy .  , 6 .  Posterior colpoperineoplasty .  , GROSS FINDINGS: The patient had a history of a rapidly growing mass on the abdomen ,  extending from the pelvis over the past two to three months .  She had a recent D&C and laparoscopy ,  and enlarged mass was noted and could not be determined if it was from the ovary or the uterus .  Curettings were negative for malignancy .  The patient did have a large cystocele and rectocele ,  and a collapsed anterior and posterior vaginal wall .  , Upon laparotomy ,  there was a giant uterine tumor extending from the pelvis up to the above the umbilicus compatible with approximately four to five-month pregnancy .  The ovaries appeared to be within normal limits .  There was marked adherence between the bladder and the giant uterus and mass with edema and inflammation ,  and during dissection ,  a laceration inadvertently occurred and it was immediately recognized .  No other pathology noted from the abdominal cavity or adhesions .  The upper right quadrant of the abdomen compatible with a previous gallbladder surgery .  The appendix is in its normal anatomic position .  The ileum was within normal limits with no Meckel's diverticulum seen and no other gross pathology evident .  There was no evidence of metastasis or tumors in the left lobe of the liver .  , Upon frozen section ,  diagnosis of initial and partial is that of a degenerating uterine fibroid rather than a malignancy .  , OPERATIVE PROCEDURE: The patient was taken to the Operating Room ,  prepped and draped in the low lithotomy position under general anesthesia .  A midline incision was made around the umbilicus down to the lower abdomen .  With a #10 Bard Parker blade knife ,  the incision was carried down through the fascia .  The fascia was incised in the midline ,  muscle fibers were splint in the midline ,  the peritoneum was grasped with hemostats and with a #10 Bard Parker blade after incision was made with Mayo scissors .  A Balfour retractor was placed into the wound .  This giant uterus was soft and compatible with a possible leiomyosarcoma or degenerating fibroid was handled with care .  The infundibular ligament on the right side was isolated and ligated with #0 Vicryl suture brought to an avascular area ,  doubly clamped and divided from the ovary and the ligament again re-ligated with #0 Vicryl suture .  The right round ligament was ligated with #0 Vicryl suture ,  brought to an avascular space within the broad ligament and divided from the uterus .  The infundibulopelvic ligament on the left side was treated in a similar fashion as well as the round ligament .  An attempt was made to dissect the bladder flap from the anterior surface of the uterus and this was remarkably edematous and difficult to do ,  and during dissection the bladder was inadvertently entered .  After this was immediately recognized ,  the bladder flap was wiped away from the anterior surface of the uterus .  The bladder was then repaired with a running locking stitch #0 Vicryl suture incorporating serosal muscularis mucosa and then the second layer of overlapping seromuscular sutures were used to make a two-layer closure of #0 Vicryl suture .  After removing the uterus ,  the bladder was tested with approximately 400 cc of sterile water and there appeared to be no leak .  Progressing and removing of the uterus was then carried out and the broad ligament was clamped bilaterally with a straight Ochsner forceps and divided from the uterus with Mayo scissors ,  and the straight Ochsner was placed by #0 Vicryl suture thus controlling the uterine blood supply .  The cardinal ligaments containing the cervical blood supply was serially clamped bilaterally with a curved Ochsner forceps ,  divided from the uterus with #10 Bard Parker blade knife and a curved Ochsner was placed by #0 Vicryl suture .  The cervix was again grasped with a Lahey tenaculum and pubovesicocervical ligament was entered and was divided using #10 Bard Parker blade knife and then the vaginal vault and with a double pointed sharp scissors .  A single-toothed tenaculum was placed on the cervix and then the uterus was removed from the vagina using hysterectomy scissors .  The vaginal cuff was then closed using a running #0 Vicryl suture in locking stitch incorporating all layers of the vagina ,  the cardinal ligaments of the lateral aspect and uterosacral ligaments on the posterior aspect .  The round ligaments were approximated to the vaginal cuff with #0 Vicryl suture and the bladder flap approximated to the round ligaments with #000 Vicryl suture .  The ______ was re-peritonealized with #000 Vicryl suture and then the cecum brought into the incision .  The pelvis was irrigated with approximately 500 cc of water .  The appendix was grasped with Babcock forceps .  The mesoappendix was doubly clamped with curved hemostats and divided with Metzenbaum scissors .  The curved hemostats were placed with #00 Vicryl suture .  The base of the appendix was ligated with #0 plain gut suture ,  doubly clamped and divided from the distal appendix with #10 Bard Parker blade knife ,  and the base inverted with a pursestring suture with #00 Vicryl .  No bleeding was noted .  Sponge ,  instrument ,  and needle counts were found to be correct .  All packs and retractors were removed .  The peritoneum muscle fascia was closed in single-layer closure using running looped #1 PDS ,  but prior to closure ,  a Marshall-Marchetti-Krantz cystourethropexy was carried out by dissecting the space of Retzius identifying the urethra in the vesical junction approximating the periurethral connective tissue to the symphysis pubis with interrupted #0 Vicryl suture .  Following this ,  the abdominal wall was closed as previously described and the skin was closed using skin staples .  Attention was then turned to the vagina ,  where the introitus of the vagina was grasped with an Allis forceps at the level of the Bartholin glands .  An incision was made between the mucous and the cutaneous junction and then a midline incision was made at the posterior vaginal mucosa in a tunneling fashion with Metzenbaum scissors .  The flaps were created bilaterally by making an incision in the posterior connective tissue of the vagina and wiping the rectum away from the posterior vaginal mucosa ,  and flaps were created bilaterally .  In this fashion ,  the rectocele was reduced and the levator ani muscles were approximated in the midline with interrupted #0 Vicryl suture .  Excess vaginal mucosa was excised and the vaginal mucosa closed with running #00 Vicryl suture .  The bulbocavernosus and transverse perinei muscles were approximated in the midline with interrupted #00 Vicryl suture .  The skin was closed with a running #000 plain gut subcuticular stitch .  The vaginal vault was packed with a Betadine-soaked Kling gauze sponge .  Sterile dressing was applied .  The patient was sent to recovery room in stable condition . \n",
      "LABEL -\tObstetrics / Gynecology, Surgery, Urology\n",
      "\n",
      "TEXT -\tclassify specialties: 1 .  The left ventricular cavity size and wall thickness appear normal .  The wall motion and left ventricular systolic function appears hyperdynamic with estimated ejection fraction of 70% to 75% .  There is near-cavity obliteration seen .  There also appears to be increased left ventricular outflow tract gradient at the mid cavity level consistent with hyperdynamic left ventricular systolic function .  There is abnormal left ventricular relaxation pattern seen as well as elevated left atrial pressures seen by Doppler examination .  , 2 .  The left atrium appears mildly dilated .  , 3 .  The right atrium and right ventricle appear normal .  , 4 .  The aortic root appears normal .  , 5 .  The aortic valve appears calcified with mild aortic valve stenosis ,  calculated aortic valve area is 1 . 3 cm square with a maximum instantaneous gradient of 34 and a mean gradient of 19 mm .  , 6 .  There is mitral annular calcification extending to leaflets and supportive structures with thickening of mitral valve leaflets with mild mitral regurgitation .  , 7 .  The tricuspid valve appears normal with trace tricuspid regurgitation with moderate pulmonary artery hypertension .  Estimated pulmonary artery systolic pressure is 49 mmHg .  Estimated right atrial pressure of 10 mmHg .  , 8 .  The pulmonary valve appears normal with trace pulmonary insufficiency .  , 9 .  There is no pericardial effusion or intracardiac mass seen .  , 10 .  There is a color Doppler suggestive of a patent foramen ovale with lipomatous hypertrophy of the interatrial septum .  , 11 .  The study was somewhat technically limited and hence subtle abnormalities could be missed from the study .  , \n",
      "LABEL -\tCardiovascular / Pulmonary, Radiology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "def clean_abstract(text):\n",
    "    text = text.split()\n",
    "    text = [x.strip() for x in text]\n",
    "    text = [x.replace('\\n', ' ').replace('\\t', ' ') for x in text]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub('([.,!?()])', r' \\1 ', text)\n",
    "    return text\n",
    "    \n",
    "\n",
    "def get_texts(df):\n",
    "    # texts = 'multilabel classification: ' + df['ABSTRACT'].apply(clean_abstract)\n",
    "    texts = 'classify specialties: ' + df['transcription'].apply(clean_abstract)\n",
    "    texts = texts.values.tolist()\n",
    "    return texts\n",
    "\n",
    "\n",
    "def get_labels(df):\n",
    "    labels = df[0].apply(', '.join)\n",
    "    labels = labels.values.tolist()\n",
    "\n",
    "    # labels =  \n",
    "    return labels\n",
    "\n",
    "\n",
    "texts = get_texts(train_df)\n",
    "labels = get_labels(train_df)\n",
    "\n",
    "for text, label in zip(texts[:2], labels[:2]):\n",
    "    print(f'TEXT -\\t{text}')\n",
    "    print(f'LABEL -\\t{label}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT9k73IR-cXi",
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "8TUCM-pH_vkj",
    "outputId": "cbf370da-011e-4d69-f067-80f60520dd3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([262., 582., 493., 335., 195.,  99.,  52.,  28.,  10.,  11.,   4.,\n",
       "          3.,   0.,   1.,   1.]),\n",
       " array([   3.        ,  201.13333333,  399.26666667,  597.4       ,\n",
       "         795.53333333,  993.66666667, 1191.8       , 1389.93333333,\n",
       "        1588.06666667, 1786.2       , 1984.33333333, 2182.46666667,\n",
       "        2380.6       , 2578.73333333, 2776.86666667, 2975.        ]),\n",
       " <BarContainer object of 15 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# text lengths\n",
    "y = [len(t.split()) for t in texts]\n",
    "x = range(0, len(y))\n",
    "plt.hist(y, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "TQ3KAWVQmDhU",
    "outputId": "5a143e9e-412f-41d9-f359-4b1d4f78f0ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([298., 750., 387., 458.,  84.,  59.,  31.,   5.,   3.,   1.]),\n",
       " array([ 1. ,  1.9,  2.8,  3.7,  4.6,  5.5,  6.4,  7.3,  8.2,  9.1, 10. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQSUlEQVR4nO3da4xd1XnG8f9THHIhLYYwtaht1UixiFAlLh1Rp1RRi0vFJYr9IUFEbbCQJfcDTUkVKXX6paoUVY5UhQSpQrIgiUkpCSVBtgJKYxmiqFKhGS4lgBMxoRDbtfGEi3NBaUrz9sMsi7Fje854zswxi/9POjprv3vts9+zpXlmz559ZlJVSJL68mujbkCSNHyGuyR1yHCXpA4Z7pLUIcNdkjq0ZNQNAJxzzjm1atWqUbchSW8ojzzyyI+qauxY606JcF+1ahUTExOjbkOS3lCSPH+8dV6WkaQOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDp0Sn1B9o1q1+b6R7Pe5LdeMZL+S3jg8c5ekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA7NGu5Jzk/y+IzHj5N8LMnZSXYmeaY9n9XmJ8ktSSaTPJHkkoV/G5KkmWYN96r6flVdVFUXAb8LvArcC2wGdlXVamBXWwa4CljdHpuAWxegb0nSCcz1ssxa4AdV9TywDtjW6tuA9W28Drijpj0ELE1y7jCalSQNZq7hfh1wVxsvq6r9bXwAWNbGy4E9M7bZ22qSpEUycLgnOR34APAvR6+rqgJqLjtOsinJRJKJqampuWwqSZrFXM7crwIeraoX2vILhy+3tOeDrb4PWDljuxWtdoSq2lpV41U1PjY2NvfOJUnHNZdw/zCvX5IB2AFsaOMNwPYZ9evbXTNrgEMzLt9IkhbBQP+sI8kZwBXAn88obwHuTrIReB64ttXvB64GJpm+s+aGoXUrSRrIQOFeVT8D3nVU7UWm7545em4BNw6lO0nSSfETqpLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHBgr3JEuT3JPke0l2J3lvkrOT7EzyTHs+q81NkluSTCZ5IsklC/sWJElHG/TM/XPAN6rqPcCFwG5gM7CrqlYDu9oywFXA6vbYBNw61I4lSbOaNdyTnAm8D7gdoKp+UVWvAOuAbW3aNmB9G68D7qhpDwFLk5w75L4lSScwyJn7ecAU8IUkjyW5LckZwLKq2t/mHACWtfFyYM+M7fe22hGSbEoykWRiamrq5N+BJOlXDBLuS4BLgFur6mLgZ7x+CQaAqiqg5rLjqtpaVeNVNT42NjaXTSVJsxgk3PcCe6vq4bZ8D9Nh/8Lhyy3t+WBbvw9YOWP7Fa0mSVoks4Z7VR0A9iQ5v5XWAk8DO4ANrbYB2N7GO4Dr210za4BDMy7fSJIWwZIB530UuDPJ6cCzwA1Mf2O4O8lG4Hng2jb3fuBqYBJ4tc2VJC2igcK9qh4Hxo+xau0x5hZw4/zakiTNh59QlaQOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjo0ULgneS7Jd5M8nmSi1c5OsjPJM+35rFZPkluSTCZ5IsklC/kGJEm/ai5n7n9UVRdV1eF/lL0Z2FVVq4FdbRngKmB1e2wCbh1Ws5Kkwcznssw6YFsbbwPWz6jfUdMeApYmOXce+5EkzdGg4V7AN5M8kmRTqy2rqv1tfABY1sbLgT0ztt3bakdIsinJRJKJqampk2hdknQ8Swac9wdVtS/JbwI7k3xv5sqqqiQ1lx1X1VZgK8D4+PictpUkndhAZ+5Vta89HwTuBS4FXjh8uaU9H2zT9wErZ2y+otUkSYtk1nBPckaSXz88Bv4EeBLYAWxo0zYA29t4B3B9u2tmDXBoxuUbSdIiGOSyzDLg3iSH5/9zVX0jyXeAu5NsBJ4Hrm3z7weuBiaBV4Ebht61JOmEZg33qnoWuPAY9ReBtceoF3DjULqTJJ0UP6EqSR0y3CWpQ4a7JHXIcJekDhnuktShQT+hKgGwavN9I9nvc1uuGcl+pTcqz9wlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KGBwz3JaUkeS/L1tnxekoeTTCb5SpLTW/2tbXmyrV+1QL1Lko5jLmfuNwG7Zyx/Gri5qt4NvAxsbPWNwMutfnObJ0laRAOFe5IVwDXAbW05wOXAPW3KNmB9G69ry7T1a9t8SdIiGfTM/bPAJ4BftuV3Aa9U1WtteS+wvI2XA3sA2vpDbf4RkmxKMpFkYmpq6uS6lyQd06zhnuT9wMGqemSYO66qrVU1XlXjY2Njw3xpSXrTG+Q/MV0GfCDJ1cDbgN8APgcsTbKknZ2vAPa1+fuAlcDeJEuAM4EXh965JOm4Zj1zr6pPVtWKqloFXAc8UFV/CjwIfLBN2wBsb+MdbZm2/oGqqqF2LUk6ofn8D9W/Br6c5FPAY8DtrX478KUkk8BLTH9D0BCN6v+YSnrjmFO4V9W3gG+18bPApceY83PgQ0PoTZJ0kvyEqiR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktShWcM9yduS/EeS/0zyVJK/a/XzkjycZDLJV5Kc3upvbcuTbf2qBX4PkqSjDHLm/j/A5VV1IXARcGWSNcCngZur6t3Ay8DGNn8j8HKr39zmSZIW0azhXtN+2hbf0h4FXA7c0+rbgPVtvK4t09avTZJhNSxJmt1A19yTnJbkceAgsBP4AfBKVb3WpuwFlrfxcmAPQFt/CHjXMV5zU5KJJBNTU1PzehOSpCMtGWRSVf0fcFGSpcC9wHvmu+Oq2gpsBRgfH6+TfZ1Vm++bbyuS1J053S1TVa8ADwLvBZYmOfzNYQWwr433ASsB2vozgReH0awkaTCD3C0z1s7YSfJ24ApgN9Mh/8E2bQOwvY13tGXa+geq6qTPzCVJczfIZZlzgW1JTmP6m8HdVfX1JE8DX07yKeAx4PY2/3bgS0kmgZeA6xagb0nSCcwa7lX1BHDxMerPApceo/5z4END6U6SdFL8hKokdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4N8g+yVyZ5MMnTSZ5KclOrn51kZ5Jn2vNZrZ4ktySZTPJEkksW+k1Iko40yJn7a8DHq+oCYA1wY5ILgM3ArqpaDexqywBXAavbYxNw69C7liSd0KzhXlX7q+rRNv4JsBtYDqwDtrVp24D1bbwOuKOmPQQsTXLusBuXJB3fnK65J1kFXAw8DCyrqv1t1QFgWRsvB/bM2Gxvq0mSFsnA4Z7kncBXgY9V1Y9nrquqAmouO06yKclEkompqam5bCpJmsVA4Z7kLUwH+51V9bVWfuHw5Zb2fLDV9wErZ2y+otWOUFVbq2q8qsbHxsZOtn9J0jEMcrdMgNuB3VX1mRmrdgAb2ngDsH1G/fp218wa4NCMyzeSpEWwZIA5lwEfAb6b5PFW+xtgC3B3ko3A88C1bd39wNXAJPAqcMMwG5YkzW7WcK+qfwNynNVrjzG/gBvn2ZckaR78hKokdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUoVnDPcnnkxxM8uSM2tlJdiZ5pj2f1epJckuSySRPJLlkIZuXJB3bIGfuXwSuPKq2GdhVVauBXW0Z4CpgdXtsAm4dTpuSpLmYNdyr6tvAS0eV1wHb2ngbsH5G/Y6a9hCwNMm5Q+pVkjSgk73mvqyq9rfxAWBZGy8H9syYt7fVfkWSTUkmkkxMTU2dZBuSpGOZ9y9Uq6qAOonttlbVeFWNj42NzbcNSdIMJxvuLxy+3NKeD7b6PmDljHkrWk2StIhONtx3ABvaeAOwfUb9+nbXzBrg0IzLN5KkRbJktglJ7gL+EDgnyV7gb4EtwN1JNgLPA9e26fcDVwOTwKvADQvQsyRpFrOGe1V9+Dir1h5jbgE3zrcp6WirNt83kv0+t+WakexXmi8/oSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6NOutkNKb2ahuwQRvw9T8eOYuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOuStkNIpyr+EqfnwzF2SOmS4S1KHDHdJ6pDhLkkdMtwlqUMLEu5Jrkzy/SSTSTYvxD4kScc39Fshk5wG/CNwBbAX+E6SHVX19LD3JWn4/EuYfViI+9wvBSar6lmAJF8G1gGGu6QT8t7+4VmIcF8O7JmxvBf4vaMnJdkEbGqLP03y/QXoZTGdA/xo1E2cQjwer/NYHOmUOx759Eh3P5/j8dvHWzGyT6hW1VZg66j2P2xJJqpqfNR9nCo8Hq/zWBzJ43GkhToeC/EL1X3AyhnLK1pNkrRIFiLcvwOsTnJektOB64AdC7AfSdJxDP2yTFW9luQvgH8FTgM+X1VPDXs/p6BuLjENicfjdR6LI3k8jrQgxyNVtRCvK0kaIT+hKkkdMtwlqUOG+zwlWZnkwSRPJ3kqyU2j7mnUkpyW5LEkXx91L6OWZGmSe5J8L8nuJO8ddU+jlOSv2tfJk0nuSvK2Ufe0WJJ8PsnBJE/OqJ2dZGeSZ9rzWcPan+E+f68BH6+qC4A1wI1JLhhxT6N2E7B71E2cIj4HfKOq3gNcyJv4uCRZDvwlMF5Vv8P0DRfXjbarRfVF4MqjapuBXVW1GtjVlofCcJ+nqtpfVY+28U+Y/uJdPtquRifJCuAa4LZR9zJqSc4E3gfcDlBVv6iqV0ba1OgtAd6eZAnwDuC/R9zPoqmqbwMvHVVeB2xr423A+mHtz3AfoiSrgIuBh0fcyih9FvgE8MsR93EqOA+YAr7QLlPdluSMUTc1KlW1D/gH4IfAfuBQVX1ztF2N3LKq2t/GB4Blw3phw31IkrwT+Crwsar68aj7GYUk7wcOVtUjo+7lFLEEuAS4taouBn7GEH/sfqNp15PXMf1N77eAM5L82Wi7OnXU9H3pQ7s33XAfgiRvYTrY76yqr426nxG6DPhAkueALwOXJ/mn0bY0UnuBvVV1+Ce5e5gO+zerPwb+q6qmqup/ga8Bvz/inkbthSTnArTng8N6YcN9npKE6Wuqu6vqM6PuZ5Sq6pNVtaKqVjH9i7IHqupNe2ZWVQeAPUnOb6W1vLn/9PUPgTVJ3tG+btbyJv4Fc7MD2NDGG4Dtw3phw33+LgM+wvRZ6uPtcfWom9Ip46PAnUmeAC4C/n607YxO+wnmHuBR4LtM58+b5k8RJLkL+Hfg/CR7k2wEtgBXJHmG6Z9stgxtf/75AUnqj2fuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR16P8Bg9Uih8hD5a4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label lengths\n",
    "y = [len(l.split()) for l in labels]\n",
    "x = range(0, len(y))\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dp75He4ASYG"
   },
   "source": [
    "\n",
    "We chose 512 for **src MAX_LENGTH** and 16 for **tgt MAX_LENGTH** \n",
    "- src - transcription \n",
    "- tgt - labels (specialties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZI7LZDlAdLX",
    "tags": []
   },
   "source": [
    "## Config\n",
    "Class defining hyper paramters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F5MG2LCST-Co"
   },
   "outputs": [],
   "source": [
    "# # small x1\n",
    "# class Config:\n",
    "#     def __init__(self):\n",
    "#         super(Config, self).__init__()\n",
    "\n",
    "#         self.SEED = 42\n",
    "#         self.MODEL_PATH = 't5-small'\n",
    "\n",
    "#         # data\n",
    "#         self.TOKENIZER = T5Tokenizer.from_pretrained(self.MODEL_PATH)\n",
    "#         self.SRC_MAX_LENGTH = 512\n",
    "#         self.TGT_MAX_LENGTH = 16\n",
    "#         self.BATCH_SIZE = 16\n",
    "#         self.VALIDATION_SPLIT = 0.25\n",
    "\n",
    "#         # model\n",
    "#         self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#         self.FULL_FINETUNING = True\n",
    "#         self.LR = 3e-5\n",
    "#         self.OPTIMIZER = 'AdamW'\n",
    "#         self.CRITERION = 'BCEWithLogitsLoss'\n",
    "#         self.SAVE_BEST_ONLY = True\n",
    "#         self.N_VALIDATE_DUR_TRAIN = 1\n",
    "#         self.EPOCHS = 20\n",
    "\n",
    "# base x1\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        super(Config, self).__init__()\n",
    "\n",
    "        self.SEED = 42\n",
    "        self.MODEL_PATH = 't5-base'\n",
    "\n",
    "        # data\n",
    "        self.TOKENIZER = T5Tokenizer.from_pretrained(self.MODEL_PATH)\n",
    "        self.SRC_MAX_LENGTH = 512\n",
    "        self.TGT_MAX_LENGTH = 16\n",
    "        self.BATCH_SIZE = 1\n",
    "        self.GRAD_ACCUM = 1\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        \n",
    "\n",
    "        # model\n",
    "        self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.FULL_FINETUNING = True\n",
    "        self.LR = 3e-5\n",
    "        self.OPTIMIZER = 'AdamW'\n",
    "        self.CRITERION = 'BCEWithLogitsLoss'\n",
    "        self.SAVE_BEST_ONLY = True\n",
    "        self.N_VALIDATE_DUR_TRAIN = 1\n",
    "        self.EPOCHS = 20\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1AhmXnXByg5",
    "tags": []
   },
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwrzxPV8B1Es"
   },
   "source": [
    "create a custom Dataset class using PyTorch Dataset class. We'll be using the **T5 tokenizer** that returns **input_ids** and **attention_mask**.\\\n",
    "The custom Dataset class will return a dict containing - <br>\n",
    "\n",
    "- src_input_ids\n",
    "- src_attention_mask\n",
    "- tgt_input_ids\n",
    "- tgt_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "62kL6XSQUon-"
   },
   "outputs": [],
   "source": [
    "class T5Dataset(Dataset):\n",
    "    def __init__(self, df, indices, set_type=None):\n",
    "        super(T5Dataset, self).__init__()\n",
    "\n",
    "        df = df.iloc[indices]\n",
    "        self.texts = get_texts(df)\n",
    "        self.set_type = set_type\n",
    "        if self.set_type != 'test':\n",
    "            self.labels = get_labels(df)\n",
    "\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.src_max_length = config.SRC_MAX_LENGTH\n",
    "        self.tgt_max_length = config.TGT_MAX_LENGTH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        src_tokenized = self.tokenizer.encode_plus(\n",
    "            self.texts[index], \n",
    "            max_length=self.src_max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        src_input_ids = src_tokenized['input_ids'].squeeze()\n",
    "        src_attention_mask = src_tokenized['attention_mask'].squeeze()\n",
    "\n",
    "        if self.set_type != 'test':\n",
    "            tgt_tokenized = self.tokenizer.encode_plus(\n",
    "                self.labels[index], \n",
    "                max_length=self.tgt_max_length,\n",
    "                # pad_to_max_length=True,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=False,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            tgt_input_ids = tgt_tokenized['input_ids'].squeeze()\n",
    "            tgt_attention_mask = tgt_tokenized['attention_mask'].squeeze()\n",
    "\n",
    "            return {\n",
    "                'src_input_ids': src_input_ids.long(),\n",
    "                'src_attention_mask': src_attention_mask.long(),\n",
    "                'tgt_input_ids': tgt_input_ids.long(),\n",
    "                'tgt_attention_mask': tgt_attention_mask.long()\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'src_input_ids': src_input_ids.long(),\n",
    "            'src_attention_mask': src_attention_mask.long()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxKmWbIICgWv"
   },
   "source": [
    "**T5Dataset** Class takes as input the **dataframe**, **indices** & **set_type**. \n",
    "We use indices list to split train / val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xkGLwcZ0f732"
   },
   "outputs": [],
   "source": [
    "# train-val split\n",
    "\n",
    "np.random.seed(config.SEED)\n",
    "\n",
    "dataset_size = len(train_df)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(config.VALIDATION_SPLIT * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OslH-HOECxRO"
   },
   "source": [
    "Here we'll initialize PyTorch DataLoader objects for the training & validation data.<br>\n",
    "These dataloaders allow us to iterate over them during training, validation or testing and return a batch of the Dataset class outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mnuNOKmkc1R",
    "outputId": "196a52a7-87da-4b58-833c-5c91d7f5330a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_input_ids shape: torch.Size([1, 512])\n",
      "src_attention_mask shape: torch.Size([1, 512])\n",
      "tgt_input_ids shape: torch.Size([1, 16])\n",
      "tgt_attention_mask shape: torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "train_data = T5Dataset(train_df, train_indices)\n",
    "val_data = T5Dataset(train_df, val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=config.BATCH_SIZE)\n",
    "\n",
    "b = next(iter(train_dataloader))\n",
    "for k, v in b.items():\n",
    "    print(f'{k} shape: {v.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feB5OEdeoV91",
    "tags": []
   },
   "source": [
    "## Model\n",
    "Our model uses pretrained T5 model with a Conditional Generation Head, from Huggingface transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "d1xG8CCdlgge"
   },
   "outputs": [],
   "source": [
    "class T5Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(T5Model, self).__init__()\n",
    "\n",
    "        self.t5_model = T5ForConditionalGeneration.from_pretrained(config.MODEL_PATH)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids, \n",
    "        attention_mask=None, \n",
    "        decoder_input_ids=None, \n",
    "        decoder_attention_mask=None, \n",
    "        lm_labels=None\n",
    "        ):\n",
    "\n",
    "        return self.t5_model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            # lm_labels=lm_labels,\n",
    "            labels=lm_labels,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiypz6jrG9bl",
    "outputId": "bd790819-dfe4-41c2-9074-375acd96e2e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = config.DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5LkYPeTqpDP",
    "tags": []
   },
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKZQM2E2DnjO"
   },
   "source": [
    "Our engine consists of the training and validation step functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xi7ZrcylE18g"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_ohe(x):\n",
    "    clean_x = [xl.replace('<pad>', '').replace('</s>', '').replace(' ', '') for xl in x]\n",
    "    y = [labels.split(',') for labels in clean_x]\n",
    "    ohe = []\n",
    "    for labels in y:\n",
    "        # print(\"predicted labels: \", labels)\n",
    "        temp = [0] * len(labels_list)\n",
    "        for label in labels:\n",
    "            idx = labels_li_indices.get(label.lower(), -1)\n",
    "            # print(\"label: \", label, \"idx: \", idx)\n",
    "            if idx != -1:\n",
    "                temp[idx] = 1\n",
    "        ohe.append(temp)\n",
    "    ohe = np.array(ohe)\n",
    "    return ohe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use F1 score for evaluation. We calculate both micro and macro, but our target is to maximize macro f1, which gives equal weight to rare and common specialties. \\\n",
    "Since the dataset is highly imbalanced, we may see large difference between the two metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HG9J7OFEDsSB"
   },
   "outputs": [],
   "source": [
    "def val(model, val_dataloader, criterion, label_stats=False):\n",
    "    \n",
    "    val_loss = 0\n",
    "    true, pred = [], []\n",
    "    \n",
    "    # set model.eval() every time during evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        # unpack the batch contents and push them to the device (cuda or cpu).\n",
    "        b_src_input_ids = batch['src_input_ids'].to(device)\n",
    "        b_src_attention_mask = batch['src_attention_mask'].to(device)\n",
    "    \n",
    "        b_tgt_input_ids = batch['tgt_input_ids']\n",
    "        lm_labels = b_tgt_input_ids.to(device)\n",
    "        lm_labels[lm_labels[:, :] == config.TOKENIZER.pad_token_id] = -100\n",
    "\n",
    "        b_tgt_attention_mask = batch['tgt_attention_mask'].to(device)\n",
    "\n",
    "        # using torch.no_grad() during validation/inference is faster -\n",
    "        # - since it does not update gradients.\n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            outputs = model(\n",
    "                input_ids=b_src_input_ids, \n",
    "                attention_mask=b_src_attention_mask,\n",
    "                lm_labels=lm_labels,\n",
    "                decoder_attention_mask=b_tgt_attention_mask)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # get true \n",
    "            for true_id in b_tgt_input_ids:\n",
    "                true_decoded = config.TOKENIZER.decode(true_id)\n",
    "                true.append(true_decoded)\n",
    "\n",
    "            # get pred (decoder generated textual label ids)\n",
    "            pred_ids = model.t5_model.generate(\n",
    "                input_ids=b_src_input_ids, \n",
    "                attention_mask=b_src_attention_mask\n",
    "            )\n",
    "            pred_ids = pred_ids.cpu().numpy()\n",
    "            for pred_id in pred_ids:\n",
    "                pred_decoded = config.TOKENIZER.decode(pred_id)\n",
    "                pred.append(pred_decoded)\n",
    "\n",
    "    true_ohe = get_ohe(true)\n",
    "    pred_ohe = get_ohe(pred)\n",
    "    \n",
    "    if label_stats:\n",
    "        true_count = np.sum(true_ohe, axis=0)\n",
    "        pred_count = np.sum(pred_ohe, axis=0)\n",
    "        labels = [i for i in range(len(true_count))]\n",
    "        plt.bar(labels, true_count, label='true specialties count')\n",
    "        plt.bar(labels, pred_count, label='pred specialties count')\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print('Val loss:', avg_val_loss)\n",
    "    print('Val accuracy:', accuracy_score(true_ohe, pred_ohe))\n",
    "\n",
    "    val_micro_f1_score = f1_score(true_ohe, pred_ohe, average='micro')\n",
    "    val_macro_f1_score = f1_score(true_ohe, pred_ohe, average='macro')\n",
    "    print('Val micro f1 score:', val_micro_f1_score)\n",
    "    print('Val macro f1 score:', val_macro_f1_score)\n",
    "    return val_micro_f1_score, val_macro_f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HG9J7OFEDsSB"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,  \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    epoch\n",
    "    ):\n",
    "    \n",
    "    # we validate config.N_VALIDATE_DUR_TRAIN times during the training loop\n",
    "    nv = config.N_VALIDATE_DUR_TRAIN\n",
    "    temp = len(train_dataloader) // nv\n",
    "    temp = temp - (temp % 100)\n",
    "    \n",
    "    train_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, \n",
    "                                      desc='Epoch ' + str(epoch))):\n",
    "        # set model.eval() every time during training\n",
    "        model.train()\n",
    "        \n",
    "        # unpack the batch contents and push them to the device (cuda or cpu).\n",
    "        b_src_input_ids = batch['src_input_ids'].to(device)\n",
    "        b_src_attention_mask = batch['src_attention_mask'].to(device)\n",
    "    \n",
    "        lm_labels = batch['tgt_input_ids'].to(device)\n",
    "        lm_labels[lm_labels[:, :] == config.TOKENIZER.pad_token_id] = -100\n",
    "\n",
    "        b_tgt_attention_mask = batch['tgt_attention_mask'].to(device)\n",
    "\n",
    "        # clear accumulated gradients\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(input_ids=b_src_input_ids, \n",
    "                        attention_mask=b_src_attention_mask,\n",
    "                        lm_labels=lm_labels,\n",
    "                        decoder_attention_mask=b_tgt_attention_mask)\n",
    "        \n",
    "\n",
    "        loss = outputs[0] \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        #  average loss (grad accum.)\n",
    "        loss = loss / config.GRAD_ACCUM\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        if step % config.GRAD_ACCUM == 0:\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    print('Training loss:', avg_train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApdIReKk7OQJ",
    "tags": []
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvz40JjQFx-5",
    "tags": []
   },
   "source": [
    "### Loss function\n",
    "- **BCEWithLogitsLoss** - Most commonly used loss function for Multi Label Classification tasks. \n",
    "\n",
    "### Optimizer\n",
    "- **AdamW** - Commonly used optimizer. Similar to the AdaFactor that was used in T5 paper.\n",
    "\n",
    "### Scheduler\n",
    "- **get_linear_scheduler_with_warmup** from the **transformers** library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "93Qs1xH27FRe"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(\"run training\")\n",
    "    # setting a seed ensures reproducible results.\n",
    "    # seed may affect the performance too.\n",
    "    torch.manual_seed(config.SEED)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # define the parameters to be optmized -\n",
    "    # - and add regularization\n",
    "    if config.FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = optim.AdamW(optimizer_parameters, lr=config.LR)\n",
    "\n",
    "    num_training_steps = len(train_dataloader) * config.EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    max_val_macro_f1_score = 0\n",
    "    print(\"start training:\")\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        print(\"train epoch:\")\n",
    "        train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, epoch)\n",
    "        print(\"evaluate:\")\n",
    "        val_micro_f1_score, val_macro_f1_score = val(model, val_dataloader, criterion)\n",
    "        print(\"dummy test:\")\n",
    "        dummy_test(model, config.TOKENIZER)\n",
    "        \n",
    "        if config.SAVE_BEST_ONLY:\n",
    "            if val_macro_f1_score > max_val_macro_f1_score:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_val_macro_f1_score = val_macro_f1_score\n",
    "                \n",
    "\n",
    "                model_name = 't5_best_model'\n",
    "                torch.save(best_model.state_dict(), model_name + '.pt')\n",
    "\n",
    "                print(f'--- Best Model. Val loss: {max_val_macro_f1_score} -> {val_macro_f1_score}')\n",
    "                max_val_macro_f1_score = val_macro_f1_score\n",
    "\n",
    "    return best_model, best_val_macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5Model()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy test for sanity check during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eW59UrCbF_rz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> <extra_id_0> : The patient had a heart attack.<extra_id_1> : The patient had a heart attack\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> <extra_id_0> :<extra_id_1> : Classify specialties:<extra_id_2> : The patient is a 5 year old\n"
     ]
    }
   ],
   "source": [
    "def dummy_test(model, tokenizer):\n",
    "    model.eval()\n",
    "    inputs = [\"Calssify specialties: The patient had a heart attack.\",\n",
    "             \"Classify specialties: The patient is a 5 year old girl, complaining about headack.\"]\n",
    "    for transcription in inputs:\n",
    "        inp = tokenizer.encode_plus(transcription,\n",
    "                                    max_length=config.SRC_MAX_LENGTH,\n",
    "                                    padding='max_length',\n",
    "                                    # pad_to_max_length=True,\n",
    "                                    truncation=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_token_type_ids=False,\n",
    "                                    return_tensors='pt'\n",
    "                                    )\n",
    "        # print(inp)\n",
    "        src_input_ids = inp['input_ids'].to(device)\n",
    "        src_attention_mask = inp['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_ids = model.t5_model.generate(\n",
    "                input_ids=src_input_ids, \n",
    "                attention_mask=src_attention_mask\n",
    "            )\n",
    "            pred_ids = pred_ids.cpu().numpy()\n",
    "            pred_decoded = tokenizer.decode(pred_ids[0])\n",
    "\n",
    "        print(\"input: \", transcription)\n",
    "        print(\"output: \", pred_decoded)\n",
    "\n",
    "    \n",
    "dummy_test(model, config.TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144,
     "referenced_widgets": [
      "3c2d9a247866441285bc590dc8e77f4e",
      "d09f38a56d914461a5df6b14cb6b2bf1",
      "31ec9f62b4eb4530a8e1d838c416bd58",
      "84d2305d4fe746a98fa649e2c4bd959c",
      "1def0969f86d4bb088d1c709e7930e31",
      "c096e21111ee43499b42feaca1e4579f",
      "fc13149dd80646099e4daceb0069970d",
      "4d3705f3b4d34317978375ee66a0dd2e",
      "406b8a2a3eb841f6909b11dd273f4e2f",
      "f9e4dbdd8f224bf4867c1d5cf737668b",
      "4da5eb71840a4751a287670b216af3d3"
     ]
    },
    "id": "YMwlc6aG7e4I",
    "outputId": "ec79a81a-c0b2-4565-e22f-2b67b1c3b6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run training\n",
      "start training:\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2576050b9644c28903ac979bb1ce0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8385336945166454\n",
      "evaluate:\n",
      "Val loss: 0.4249023879867002\n",
      "Val accuracy: 0.43614457831325304\n",
      "Val micro f1 score: 0.6899696048632219\n",
      "Val macro f1 score: 0.3193499469253828\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model. Val loss: 0 -> 0.3193499469253828\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b491aa9ee142a6a84d86a557e232de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3941785768579977\n",
      "evaluate:\n",
      "Val loss: 0.3358515584137268\n",
      "Val accuracy: 0.5349397590361445\n",
      "Val micro f1 score: 0.7480482611781405\n",
      "Val macro f1 score: 0.45544548794756895\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model. Val loss: 0.3193499469253828 -> 0.45544548794756895\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c047f8ddfa4b31bda8f22d5cbeac51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2906024074703716\n",
      "evaluate:\n",
      "Val loss: 0.3151725315522537\n",
      "Val accuracy: 0.5518072289156627\n",
      "Val micro f1 score: 0.7736804049168474\n",
      "Val macro f1 score: 0.5107603659908908\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Orthopedic</s>\n",
      "--- Best Model. Val loss: 0.45544548794756895 -> 0.5107603659908908\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4940f9dab7684c6bbc008cc6e4d7c2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.21943543550348055\n",
      "evaluate:\n",
      "Val loss: 0.2846852308934476\n",
      "Val accuracy: 0.5975903614457831\n",
      "Val micro f1 score: 0.8014545454545455\n",
      "Val macro f1 score: 0.5276619987502772\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model. Val loss: 0.5107603659908908 -> 0.5276619987502772\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db46c4f1ddc4e289ec8706d5ef6e462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.16886430776527056\n",
      "evaluate:\n",
      "Val loss: 0.29444158515266666\n",
      "Val accuracy: 0.619277108433735\n",
      "Val micro f1 score: 0.8031609195402298\n",
      "Val macro f1 score: 0.5664377246660679\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "--- Best Model. Val loss: 0.5276619987502772 -> 0.5664377246660679\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15e2455ab2743158db9dc639b958323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.13692955300506712\n",
      "evaluate:\n",
      "Val loss: 0.3004136741918046\n",
      "Val accuracy: 0.6144578313253012\n",
      "Val micro f1 score: 0.8140556368960469\n",
      "Val macro f1 score: 0.5717755706748608\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n",
      "--- Best Model. Val loss: 0.5664377246660679 -> 0.5717755706748608\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91935d21a3fb4c7cab3809d2f9a11951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.10974250271372195\n",
      "evaluate:\n",
      "Val loss: 0.3225993276744045\n",
      "Val accuracy: 0.6481927710843374\n",
      "Val micro f1 score: 0.8224431818181818\n",
      "Val macro f1 score: 0.5911512523594658\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model. Val loss: 0.5717755706748608 -> 0.5911512523594658\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710da0f23a9a4deab7863992b2ade960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.08233861585834729\n",
      "evaluate:\n",
      "Val loss: 0.33574699894630744\n",
      "Val accuracy: 0.6602409638554216\n",
      "Val micro f1 score: 0.837473385379702\n",
      "Val macro f1 score: 0.6262702075853831\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "--- Best Model. Val loss: 0.5911512523594658 -> 0.6262702075853831\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a5d410dedd443985c09afe61c10faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.07389040616252923\n",
      "evaluate:\n",
      "Val loss: 0.348416161140451\n",
      "Val accuracy: 0.6313253012048192\n",
      "Val micro f1 score: 0.8134863701578191\n",
      "Val macro f1 score: 0.5849918456599277\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06501d0d729f497982a791d92fbdc946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.06426471021385449\n",
      "evaluate:\n",
      "Val loss: 0.37814224199982743\n",
      "Val accuracy: 0.6289156626506024\n",
      "Val micro f1 score: 0.8147612156295224\n",
      "Val macro f1 score: 0.6072968473739686\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4dc54877044958bfa379a65317aa5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.047367632667333466\n",
      "evaluate:\n",
      "Val loss: 0.3671876223452229\n",
      "Val accuracy: 0.6433734939759036\n",
      "Val micro f1 score: 0.822695035460993\n",
      "Val macro f1 score: 0.6046047775966376\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707cf58a3cc6404dadd81a8dff012e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.04244397023404313\n",
      "evaluate:\n",
      "Val loss: 0.37474984023706437\n",
      "Val accuracy: 0.6433734939759036\n",
      "Val micro f1 score: 0.8217609162491053\n",
      "Val macro f1 score: 0.609781955316902\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922eac4db1414d2baf93568ef2183abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03401028180288624\n",
      "evaluate:\n",
      "Val loss: 0.38349244181450143\n",
      "Val accuracy: 0.6506024096385542\n",
      "Val micro f1 score: 0.8288920056100981\n",
      "Val macro f1 score: 0.6297593090136293\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model. Val loss: 0.6262702075853831 -> 0.6297593090136293\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e476789b624cecad67937e7ef31277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.031005937397028022\n",
      "evaluate:\n",
      "Val loss: 0.3925453853230268\n",
      "Val accuracy: 0.6457831325301204\n",
      "Val micro f1 score: 0.8272921108742004\n",
      "Val macro f1 score: 0.6127021182049807\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01ab3269394931a06738b3de695d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02344069308011643\n",
      "evaluate:\n",
      "Val loss: 0.4200558671619355\n",
      "Val accuracy: 0.6481927710843374\n",
      "Val micro f1 score: 0.8294736842105263\n",
      "Val macro f1 score: 0.6265803510713274\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c57c769202c42f8aefbd64a02a55bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.021346518578800672\n",
      "evaluate:\n",
      "Val loss: 0.412597765048988\n",
      "Val accuracy: 0.6433734939759036\n",
      "Val micro f1 score: 0.8239436619718309\n",
      "Val macro f1 score: 0.6151040863944025\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dde14308ed54bf7bd666a3d2be573f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.017905857973524113\n",
      "evaluate:\n",
      "Val loss: 0.4262377683112681\n",
      "Val accuracy: 0.653012048192771\n",
      "Val micro f1 score: 0.829639889196676\n",
      "Val macro f1 score: 0.6292913960491519\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee2b978a7374f0d96f91b1441d13ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.014011861460327889\n",
      "evaluate:\n",
      "Val loss: 0.43268926860948986\n",
      "Val accuracy: 0.653012048192771\n",
      "Val micro f1 score: 0.8305555555555555\n",
      "Val macro f1 score: 0.6294737333955391\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> Neurology</s>\n",
      "train epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd20d97098b947eebc1dfc132d8c8509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0135937547616771\n",
      "evaluate:\n",
      "Val loss: 0.4460605543904339\n",
      "Val accuracy: 0.6506024096385542\n",
      "Val micro f1 score: 0.8293020041465101\n",
      "Val macro f1 score: 0.6352388885151725\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model. Val loss: 0.6297593090136293 -> 0.6352388885151725\n",
      "train epoch:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d9b177c3644c31a15828088ab25e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/1661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.012089074333362418\n",
      "evaluate:\n",
      "Val loss: 0.4382678328608952\n",
      "Val accuracy: 0.6674698795180722\n",
      "Val micro f1 score: 0.8370473537604456\n",
      "Val macro f1 score: 0.639998443989698\n",
      "dummy test:\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n",
      "--- Best Model. Val loss: 0.6352388885151725 -> 0.639998443989698\n"
     ]
    }
   ],
   "source": [
    "best_model, best_val_macro_f1_score = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best macro f1:  0.639998443989698\n",
      "input:  Calssify specialties: The patient had a heart attack.\n",
      "output:  <pad> Cardiovascular / Pulmonary</s>\n",
      "input:  Classify specialties: The patient is a 5 year old girl, complaining about headack.\n",
      "output:  <pad> General Medicine</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"best macro f1: \", best_val_macro_f1_score) \n",
    "dummy_test(best_model, config.TOKENIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f4kLd1OGes-",
    "tags": []
   },
   "source": [
    "## Submission\n",
    "Download and evaluate submission model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doenload trained model\n",
    "# https://drive.google.com/file/d/1ONzcbO06kIzrA5t8W-os7Jp-jvwXNb0Y/view?usp=sharing\n",
    "# https://drive.google.com/file/d/1ONzcbO06kIzrA5t8W-os7Jp-jvwXNb0Y/view?usp=sharing\n",
    "!gdown --id 1ONzcbO06kIzrA5t8W-os7Jp-jvwXNb0Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (t5_model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_model = T5Model()\n",
    "submission_model.load_state_dict(torch.load('t5_submission_model.pt'))\n",
    "submission_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JI-MUk0i-FHH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  <pad> Ophthalmology, Surgery</s>  ground truths:  ['Ophthalmology, Surgery</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Ophthalmology, Surgery</s>  ground truths:  ['Ophthalmology, Surgery</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Cardiovascular / Pulmonary, Surgery</s>  ground truths:  ['Cardiovascular / Pulmonary, Surgery</s> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> General Medicine</s>  ground truths:  ['General Medicine</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Gastroenterology, Surgery</s>  ground truths:  ['Gastroenterology, Surgery</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Neurology</s>  ground truths:  ['Neurology</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Surgery, Urology</s>  ground truths:  ['Surgery, Urology</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Gastroenterology, Surgery</s>  ground truths:  ['Gastroenterology</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Neurology</s>  ground truths:  ['Neurology</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Cardiovascular / Pulmonary, Radiology</s>  ground truths:  ['Cardiovascular / Pulmonary, Radiology</s> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Cardiovascular / Pulmonary, Radiology</s>  ground truths:  ['Cardiovascular / Pulmonary, Radiology</s> <pad> <pad> <pad> <pad> <pad>']\n",
      "predictions:  <pad> Cardiovascular / Pulmonary, Office Notes</s>  ground truths:  ['Cardiovascular / Pulmonary</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>']\n"
     ]
    }
   ],
   "source": [
    "# evaluation samples\n",
    "\n",
    "# evaluate\n",
    "def eval_sample(model):\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        pred = []\n",
    "        true = []\n",
    "        b_src_input_ids = batch['src_input_ids'].to(device)\n",
    "        b_src_attention_mask = batch['src_attention_mask'].to(device)\n",
    "        b_tgt_input_ids = batch['tgt_input_ids']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # get pred\n",
    "            pred_ids = model.t5_model.generate(\n",
    "                input_ids=b_src_input_ids, \n",
    "                attention_mask=b_src_attention_mask\n",
    "            )\n",
    "            pred_ids = pred_ids.cpu().numpy()\n",
    "            for pred_id in pred_ids:\n",
    "                pred_decoded = config.TOKENIZER.decode(pred_id)\n",
    "                pred.append(pred_decoded)\n",
    "\n",
    "\n",
    "        for true_id in b_tgt_input_ids:\n",
    "            true_decoded = config.TOKENIZER.decode(true_id)\n",
    "            true.append(true_decoded)\n",
    "\n",
    "\n",
    "        print(\"predictions: \", pred_decoded, \" ground truths: \", true)\n",
    "        if i > 10: break\n",
    "\n",
    "\n",
    "eval_sample(submission_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4382678328608952\n",
      "Val accuracy: 0.6674698795180722\n",
      "Val micro f1 score: 0.8370473537604456\n",
      "Val macro f1 score: 0.639998443989698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hagaymi/nym/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8370473537604456, 0.639998443989698)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate submission F1 on validation set:\n",
    "val(submission_model, val_dataloader, nn.BCEWithLogitsLoss(), label_stats=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85eiHIMXKAz_"
   },
   "source": [
    "# References:\n",
    "- notebook: \"T5 - Multi Label Classification\"\n",
    "https://www.kaggle.com/prithvijaunjale/t5-multi-label-classification\n",
    "\n",
    "- HuggingFace transformers:\n",
    "https://huggingface.co/transformers/\n",
    "\n",
    "- T5 paper\n",
    "https://arxiv.org/abs/1910.10683\n",
    "\n",
    "- Nym\n",
    "https://nym.health/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "notebooke964bbfca4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1def0969f86d4bb088d1c709e7930e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4da5eb71840a4751a287670b216af3d3",
      "placeholder": "​",
      "style": "IPY_MODEL_f9e4dbdd8f224bf4867c1d5cf737668b",
      "value": " 15/1557 [02:28&lt;4:07:47,  9.64s/it]"
     }
    },
    "31ec9f62b4eb4530a8e1d838c416bd58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc13149dd80646099e4daceb0069970d",
      "placeholder": "​",
      "style": "IPY_MODEL_c096e21111ee43499b42feaca1e4579f",
      "value": "Epoch 0:   1%"
     }
    },
    "3c2d9a247866441285bc590dc8e77f4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31ec9f62b4eb4530a8e1d838c416bd58",
       "IPY_MODEL_84d2305d4fe746a98fa649e2c4bd959c",
       "IPY_MODEL_1def0969f86d4bb088d1c709e7930e31"
      ],
      "layout": "IPY_MODEL_d09f38a56d914461a5df6b14cb6b2bf1"
     }
    },
    "406b8a2a3eb841f6909b11dd273f4e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3705f3b4d34317978375ee66a0dd2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4da5eb71840a4751a287670b216af3d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84d2305d4fe746a98fa649e2c4bd959c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_406b8a2a3eb841f6909b11dd273f4e2f",
      "max": 1557,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d3705f3b4d34317978375ee66a0dd2e",
      "value": 15
     }
    },
    "c096e21111ee43499b42feaca1e4579f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d09f38a56d914461a5df6b14cb6b2bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9e4dbdd8f224bf4867c1d5cf737668b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc13149dd80646099e4daceb0069970d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
